# LLM-specific R Packages {#sec-r-packages}


As you can guess, a number of packages have been developed to more easily facilitate interacting with LLMs via R. Many of these packages are useful (we'll cover some of those in the workshop), whereas other packages include some developer design decisions that don't work particularly well for my usual workflows. 

Below is a non-exhaustive list of packages that I've found to interact with LLMs. 
This is not meant to be exhaustive or a curated list; it's only to provide you with information about the packages you'll be using in the workshop (and others) in the case you find them helpful for your workflow.
All package summaries were initially generated with AI.
Some summaries have been edited, some have not.

## ellmer
**ellmer** [Overview](https://ellmer.tidyverse.org/){target="_blank"} [CRAN](https://cran.r-project.org/web/packages/ellmer/index.html){target="_blank"} [Documentation]( https://cran.r-project.org/web/packages/ellmer/refman/ellmer.html){target="_blank"}  

**ellmer** is an R package that provides a unified interface for interacting with large language models from over 17 providers including OpenAI, Anthropic, Google Gemini, and AWS Bedrock. It supports advanced features like streaming outputs, tool/function calling, structured data extraction, and multimodal inputs. Chat objects are stateful and maintain conversation context, enabling both interactive console-based conversations and programmatic use in R scripts and applications.

## tidyprompt
**tidyprompt** [Overview](https://github.com/KennispuntTwente/tidyprompt){target="_blank"} [CRAN](https://cran.r-project.org/web/packages/tidyprompt/index.html){target="_blank"} [Documentation](https://cran.r-project.org/web/packages/tidyprompt/refman/tidyprompt.html){target="_blank"}  

**tidyprompt** is an R package that provides a compositional framework (“prompt wraps”) for building prompts enriched with logic, validation, and extraction functions when interacting with LLMs. It supports structured output, retry/feedback loops, reasoning strategies (e.g. ReAct or chain-of-thought), and even autonomous R code or function calling as part of an LLM dialogue. The package is provider-agnostic, meaning its features can layer on top of any chat completion API (e.g. via ellmer) to produce more robust, predictable interactions.

