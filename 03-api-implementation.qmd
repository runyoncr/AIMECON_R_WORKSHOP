# API Implementation

Arguably the most popular method for interacting with a generative AI model is a simple chatbot-based interface.
These interfaces support a conversational interactions with LLM much like a text conversation or Teams chat (or AOL Instant Messaging). 
There is a text box, you enter a prompt, the model processes that prompt, and provides a response. And continue.

This method of interacting with a generative AI model has many advantages, the most salient of which is ease of interaction. 
It's easy have a back-and-forth conversation, and many of the model providers have made it so you can continue old conversations or search through previous conversations.

However, for certain tasks (e.g., repetitive tasks to be completed at scale), the chatbot interface can be inefficient. It can be time consuming to copy-cut-paste-submit-copy-cut-paste - and repeat - for the _n_ number of times you need to complete a task.

